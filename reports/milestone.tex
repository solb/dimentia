\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{color}
\usepackage{listings}
\usepackage{cleveref}
\usepackage{ulem}

\newcommand{\s}[1]{\textcolor{red}{#1}}
\newcommand{\m}[1]{\textcolor{green}{#1}}
\newcommand{\f}[1]{\textcolor{blue}{#1}}

\renewcommand{\labelenumi}{\arabic{enum}.\arabic{enumi}}
\renewcommand{\labelenumii}{\arabic{enumii}.}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\renewcommand{\thempfootnote}{\fnsymbol{mpfootnote}}

\lstset{language=C++,
  basicstyle=\ttfamily,
  keywordstyle=\color{blue}\ttfamily,
  stringstyle=\color{red}\ttfamily,
  commentstyle=\color{green}\ttfamily,
  morecomment=[l][\color{magenta}]{\#},
  moredelim=**[is][\color{red}]{@}{@}
}

\title{{\small 15-745: Optimizing Compilers for Modern Architectures} \\ Project Milestone Report}
\author{Sol Boucher and Goran \v{Z}u\v{z}i\'c}

\begin{document}
\maketitle

\section{Problem}

Logical bugs are a big source of programming errors and can be notoriously hard to catch.
While there is no hope to detect all logical mistakes in source code, one might hope to design bug detection software to capture a specific type of probable bugs.
To this end, we propose a static bug detection technique that uses dimensional analysis to flag possible programmer mistakes.
The technique examines variables that are related by arithmetic, assignment, and comparison operations and identifies \textit{semantic mismatches}, or places where incompatible variables (those with different dimensions, or \texttt{degrees}) become associated.
Unlike prior dimensional analysis contributions such as \cite{hilfinger1988ada}, this method doesn't require the programmer to supply annotations.
The price for this increased usability is that, instead of understanding what type of data a variable contains, our tool can only predict in what ways it \textit{might} be valid to use a particular variable.
However, we believe this accuracy tradeoff is reasonable in certain scenarios; for instance, in competitive programming contexts where time is critically important, it can offer basic semantic checking with little or no extra effort.

% TODO: Has anything changed based upon feedback from your proposal or as a result of your research so far?
% TODO: Describe our rules for handling various types of instructions, along with any optimizations (e.g. ignoring reflexive equalities).

\section{Goals and progress}

Below, we provide our goals for this project. If the problem is more challenging than we expect, we will only complete the 75\% goals; if the project is roughly as challenging as we expect, then we will complete some subset of the 100\% goals; and, if we make progress at a quicker rate than anticipated, we will consider some of the 125\% goals.
\begin{description}
\item [75\% goal] If the dimensional analysis proves too hard or produces too many false-positives to be useful we will consider a reduced-scope problem of ``mod-consistency-detection''. Basically, each time a variable stores a value that modulo some $P$, we are to expect that this variable will always contain some value calculated modulo $P$. If it appears this is not the case, we issue a warning. This problem can be viewed not only as a semantic bug detection, but also as a dimensional analysis problem if we consider ``int modulo P'' as a separate type.

\item [100\% goal] We would like to have a working dimensional analysis tool that will produce useful debugging output when given as input a contest problem with a dimensional analysis bug. Additionally, if the framework appears too-impractical, we might consider adding some programmer-annotation tools to help guide the analysis. 

\item [125\% goal] As our most ambitious goal, we will try to design a practical framework that could be fed mature software codebases and have a reasonable output.
\end{description}

\subsection{Resources and Project Timeline}

We're building a proof-of-concept system implemented as two LLVM pure analysis passes.
The decision to operate on LLVM IR was made in order to keep the code applicable to multiple languages, although we're currently only testing on basic C code.

In order to ensure we'll be able to produce meaningful error messages, we use the debugging annotations generated by Clang to associate groups of registers with their corresponding C variables.
To this end, we've built an analysis pass that builds a mapping between LLVM Value objects and the debug intrinsics for high-level variables; our primary pass then uses these associations as it processes each instruction and builds a set of linear equations associating separate variables' degrees.
We'll soon be using more of the information contained in the debug intrinsics to generate error messages that identify source locations where semantic mismatches occurred.

% TODO: Discuss merging and temporaries.

After we've processed a whole compilation unit's relevant instructions and generated a system of equations describing its variables' relative degrees, we repeatedly run a matrix-based linear solver on them.
If we are unable to find a solution, we flag a possible semantic mismatch.

% TODO: Treat this more thoroughly.

Below is an updated progress timeline.
\sout{Strikethroughs} indicate a task is complete, \underline{underlines} mean it's in progress, and \textit{italics} indicate adjustments to the original schedule.

% TODO: Update this progress visualization.

\noindent
\begin{tabular}{c | l}
Week of & Task \\
\hline
3/21 & \sout{Become familiar with LLVM IR debugging information,} \\
& \sout{Finish collecting basic test/evaluation dataset and try the algorithm out by hand} \\
3/28 & \sout{Be able to group registers by variable and represent variables' dimensionalities,} \\
& \sout{Enumerate rules for updating dimensionalities based on the arithmetic operations present} \\
4/4 & \underline{Be able to partially analyze toy examples and detect obvious dimensionality mismatches} \\
& \underline{Start to get a sense of the false negative/false positive rate} \\
4/11 & \textbf{Milestone report due.}, \underline{Continue development,} \\
& Develop basic heuristics to prune false positives if needed \\
4/18 & Achieve enough functionality to be able to run on arbitrary code samples, \\
& Work on presenting suspected errors reasonably to the user \\
4/25 & \textbf{Poster session at end of week.} Experiment on our full dataset, Prepare poster, and \\
& Perform a case study in actually debugging unfamiliar code with the tool \\
5/2 & \textbf{Final report due.} Produce final report
\end{tabular}

\section{Evaluation Plan}

As a evaluation method we are still considering downloading a vast amount of source codes from open competitive programming sites like \texttt{codeforces.com} and finding dimensional bugs.
Obvisouly, such evaluation will require a lot of manual labor of checking for false-positives and it is not clear what is the probability that a random source code contains a dimensional-analysis bug. However, our hope is to find a nontrivial number of bugs and present a case study in which we use the tool to find them.
Specifically, we're interested in seeing the false positive rate, false negative rate, and applicability of our checker to the debugging efforts of a programmer unfamiliar with the code.

Since we're still focused on correctness and only starting to think about false positives, the evaluation is yet to come.

\section{Project and Progress Concerns}

While we haven't hit any major stumbling blocks to date, it's clear that the project is behind schedule.
Getting back on track is going to require a time investment following the exam, because the evaluation portion of the work will be time-consuming and relies on a completed prototype with false-positive pruning.

% TODO: Anything we want to add here?

%%%%%%%%%%%%%%%%%%%%%%%% references %%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{abbrv}
\bibliography{refs}

\end{document}
