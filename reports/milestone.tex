\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage[margin=1in]{geometry}
\usepackage{gensymb}
\usepackage{graphicx}
\usepackage{color}
\usepackage{listings}
\usepackage{cleveref}
\usepackage{ulem}

\newcommand{\s}[1]{\textcolor{red}{#1}}
\newcommand{\m}[1]{\textcolor{green}{#1}}
\newcommand{\f}[1]{\textcolor{blue}{#1}}

\renewcommand{\labelenumi}{\arabic{enum}.\arabic{enumi}}
\renewcommand{\labelenumii}{\arabic{enumii}.}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\renewcommand{\thempfootnote}{\fnsymbol{mpfootnote}}

\lstset{language=C++,
  basicstyle=\ttfamily,
  keywordstyle=\color{blue}\ttfamily,
  stringstyle=\color{red}\ttfamily,
  commentstyle=\color{green}\ttfamily,
  morecomment=[l][\color{magenta}]{\#},
  moredelim=**[is][\color{red}]{@}{@}
}

\title{{\small 15-745: Optimizing Compilers for Modern Architectures} \\ Project Milestone Report}
\author{Sol Boucher and Goran \v{Z}u\v{z}i\'c}

\begin{document}
\maketitle

\section{Problem}

Logical bugs are a big source of programming errors and can be notoriously hard to catch.
While there is no hope of detecting all logical mistakes in source code, one can try to design specialized software to detect a specific class of probable bug.
To this end, we propose a static bug detection technique that uses dimensional analysis to flag possible programmer mistakes.
The technique examines variables that are related by arithmetic, assignment, and comparison operations and identifies \textit{semantic mismatches}, or places where incompatible variables (those with different dimensions, or \textit{degrees}) become associated.

Unlike prior dimensional analysis contributions such as \cite{hilfinger1988ada}, this method doesn't require the programmer to supply annotations.
The price for this increased usability is that, instead of understanding what type of data a variable contains, our tool can only predict in what ways it \textit{might} be valid to use a particular variable.
However, we believe this accuracy tradeoff is reasonable in certain scenarios; for instance, in competitive programming contexts where time is critically important, it can offer basic semantic checking with little or no extra effort.

Our experience thus far points to the approach's feasibility without any major changes.
If $x$ is a register or variable and $\degree(x)$ is the degree of $x$, our implementation currently understands the following equivalences between classes of LLVM IR assembly instructions and registers/variables' relative degrees:
\[y = \mathtt{load}\ x \implies \degree(y)\ =\ \degree(x)\]
\[\mathtt{store}\ x,\ y \implies \degree(y)\ =\ \degree(x)\]
\[z = \mathtt{add}\ x,\ y \implies \degree(z)\ =\ \degree(x)\ =\ \degree(y)\]
\[z = \mathtt{sub}\ x,\ y \implies \degree(z)\ =\ \degree(x)\ =\ \degree(y)\]
\[z = \mathtt{mul}\ x,\ y \implies \degree(z)\ =\ \degree(x)\ +\ \degree(y)\]
\[z = \mathtt{div}\ x,\ y \implies \degree(z)\ =\ \degree(x)\ -\ \degree(y)\]

Most notably, we still need to handle comparison instructions and add support for at least some non-scalar datatypes.

\section{Goals and progress}

Below, we provide our goals for this project. If the problem is more challenging than we expect, we will only complete the 75\% goals; if the project is roughly as challenging as we expect, then we will complete some subset of the 100\% goals; and, if we make progress at a quicker rate than anticipated, we will consider some of the 125\% goals.
\begin{description}
\item [75\% goal] If the dimensional analysis proves too hard or produces too many false-positives to be useful we will consider a reduced-scope problem of ``mod-consistency-detection''. Basically, each time a variable stores a value modulo some $P$, we are to expect that this variable will always contain some value calculated modulo $P$. If it appears this is not the case, we issue a warning. This problem can be viewed not only as a semantic bug detection, but also as a dimensional analysis problem if we consider ``int modulo P'' as a separate type.

\item [100\% goal] We would like to have a working dimensional analysis tool that will produce useful debugging output when given as input a contest problem with a dimensional analysis bug. Additionally, if the framework appears too-impractical, we might consider adding some programmer-annotation tools to help guide the analysis. 

\item [125\% goal] As our most ambitious goal, we will try to design a practical framework that could be fed mature software codebases and have a reasonable output.
\end{description}

\subsection{Progress and Project Timeline}

At a high level, our primary goal is to associate a degree (integral dimension) with each variable (and temporary) in the program and infer which variables definitely have dimension 0. They are a source of potential bugs.

We have built a simple proof-of-concept system implemented as two LLVM pure analysis passes.
The decision to operate on LLVM IR was made in order to keep the code applicable to multiple languages, although we're currently only testing on basic C code.

In order to ensure we'll be able to produce meaningful error messages, we use the debugging annotations generated by Clang to associate groups of registers with their corresponding C variables.
To this end, we've built an analysis pass that builds a mapping between LLVM Value objects and the debug intrinsics for high-level variables; our primary pass then uses these associations as it processes each instruction and builds a set of linear equations associating separate variables' degrees.

The linear equations are built by examining relations between variables/temporaries. After we've processed a whole compilation unit's relevant instructions and generated a system of equations describing its variables' relative degrees, we compute the set of consistent degrees of the system by a singular value decomposition using LAPACK. Each variable that always has degree 0 in the set of consistent degrees is marked as a potential bug.

While we have this preliminary version working, there are a lot of interesting subproblems that need to be handled, for instance:
\begin{itemize}
  \item a variable stored/loaded to the same location has the same degree (handled)
  \item a result of the function has the same degree (not handled)
  \item same field of the same structure always have the same degree (not handled)
  \item array elements have the same degree (not handled)
\end{itemize}

Furthermore, after we find the dimensionless variables, we need to run a thorough filtering process because of false-positives. We have not implemented them yet. However, here is a relevant list of heuristics that we might end up using:
\begin{itemize}
  \item induction variables are almost always dimensionless and we should filter them from the results
  \item anything that is marked dimensionless directly by a induction variable (for instance, by adding it to a induction variable) is meant to be dimensionless, and should not be reported
  \item even when a bug is found, we usually find a (large) set of dimensionless variables that are dimensionless for the same reason; perhaps we should group them somehow
\end{itemize}

Below is an updated progress timeline.
\sout{Strikethroughs} indicate a task is complete.

\noindent
\begin{tabular}{c | l}
Week of & Task \\
\hline
3/21 & \sout{Become familiar with LLVM IR debugging information,} \\
& \sout{Finish collecting basic test/evaluation dataset and try the algorithm out by hand} \\
3/28 & \sout{Be able to group registers by variable and represent variables' dimensionalities,} \\
& \sout{Enumerate rules for updating dimensionalities based on the arithmetic operations present} \\
4/4 & \sout{Be able to partially analyze toy examples and detect obvious dimensionality mismatches} \\
& \sout{Start to get a sense of the false negative/false positive rate} \\
4/11 & \textbf{Milestone report due.} \\
& Develop basic heuristics to prune false positives if needed \\
4/18 & Achieve enough functionality to be able to run on arbitrary code samples, \\
& Work on presenting suspected errors reasonably to the user \\
4/25 & \textbf{Poster session at end of week.} Experiment on our full dataset, Prepare poster, and \\
& Perform a case study in actually debugging unfamiliar code with the tool \\
5/2 & \textbf{Final report due.} Produce final report
\end{tabular}

\section{Evaluation Plan}

As a evaluation method we are still considering downloading a vast amount of source codes from open competitive programming sites like \texttt{codeforces.com} and finding dimensional bugs.
Obviously, such evaluation will require a lot of manual labor of checking for false-positives and it is not clear what is the probability that a random source code contains a dimensional-analysis bug. However, our hope is to find a nontrivial number of bugs and present a case study in which we use the tool to find them.
Specifically, we're interested in seeing the false positive rate, false negative rate, and applicability of our checker to the debugging efforts of a programmer unfamiliar with the code.

Since we're still focused on correctness and only starting to think about false positives, the evaluation is yet to come.

\section{Project and Progress Concerns}

While we haven't hit any major stumbling blocks to date, the laborious part of improving the quality of our reported results is ahead of us. So far we are able to cope only with toy examples as many language constructs have not been addressed. We hope to do as much as possible to get a reasonable tool.

\bibliographystyle{abbrv}
\bibliography{refs}

\end{document}
